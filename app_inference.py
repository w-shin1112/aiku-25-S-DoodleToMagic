import gradio as gr
from PIL import Image
import torch
import os
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, DPMSolverMultistepScheduler
from peft import PeftModel

# ------------------------------------------------------
# ëª¨ë¸ ê²½ë¡œ ë° ì„¤ì •
# ------------------------------------------------------
POKEMON_LORA_PATH = "/home/aikusrv04/Doodle/FINAL/model/pokemon"
AMATEUR_LORA_PATH = "/home/aikusrv04/Doodle/FINAL/model/amateur"

guidance_scale = 7.5
controlnet_scale = 1.0
steps = 20
POKEMON_SEED = 456
AMATEUR_SEED = 42

# ------------------------------------------------------
# ë””ë°”ì´ìŠ¤ ì„¤ì •
# ------------------------------------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ------------------------------------------------------
# ControlNet + Stable Diffusion íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
# ------------------------------------------------------
def load_pipeline(lora_path=None):
    controlnet = ControlNetModel.from_pretrained(
        "lllyasviel/control_v11p_sd15_scribble",
        torch_dtype=torch.float16
    )

    pipe = StableDiffusionControlNetPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        controlnet=controlnet,
        torch_dtype=torch.float16,
        safety_checker=None,
        requires_safety_checker=False
    )

    # LoRA ì ìš©
    if lora_path and os.path.exists(lora_path):
        print(f"ğŸ”„ Loading LoRA weights from {lora_path}")
        pipe.unet = PeftModel.from_pretrained(pipe.unet, lora_path)
    else:
        print(f"âš ï¸ LoRA weights not found at {lora_path}, using base model")

    pipe = pipe.to(device)
    pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
    return pipe

# ------------------------------------------------------
# ëª¨ë¸ ìºì‹±
# ------------------------------------------------------
pokemon_pipe = load_pipeline(POKEMON_LORA_PATH)
amateur_pipe = load_pipeline(AMATEUR_LORA_PATH)

# ------------------------------------------------------
# Inference í•¨ìˆ˜ (ì‹¤ì‹œê°„ ì§„í–‰ë¥  í‘œì‹œ)
# ------------------------------------------------------
def run_inference(category, mode, sketch, uploaded, description):
    try:
        # ì…ë ¥ ì´ë¯¸ì§€ í™•ì¸
        image = None
        if mode == "ìŠ¤ì¼€ì¹˜ ì‚¬ìš©":
            if sketch is not None:
                if isinstance(sketch, dict):
                    if "composite" in sketch and sketch["composite"] is not None:
                        image = sketch["composite"]
                    elif "layers" in sketch and len(sketch["layers"]) > 0:
                        image = sketch["layers"][0]
                else:
                    image = sketch
        elif mode == "ì—…ë¡œë“œ ì‚¬ìš©" and uploaded is not None:
            image = uploaded

        if image is None:
            yield "âš ï¸ ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.", None
            return

        if description is None or description.strip() == "":
            yield "âš ï¸ ì´ë¯¸ì§€ ì„¤ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", None
            return

        # ì…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        image = image.convert("RGB").resize((512, 512))

        # ì¹´í…Œê³ ë¦¬ë³„ ì„¤ì •
        if category == "í¬ì¼“ëª¬":
            user_prompt = f"pokemon style, cute {description.strip()} pokemon character, no background"
            pipe = pokemon_pipe
            seed = POKEMON_SEED
        else:
            user_prompt = f"a childlike crayon drawing, cute {description.strip()} character, no background"
            pipe = amateur_pipe
            seed = AMATEUR_SEED

        # ì§„í–‰ë¥  í‘œì‹œ (steps ê¸°ì¤€)
        for i in range(1, steps + 1):
            progress = int((i / steps) * 100)
            yield f"â³ ì´ë¯¸ì§€ ìƒì„± ì¤‘... ", None

        # ì´ë¯¸ì§€ ìƒì„±
        result = pipe(
            prompt=user_prompt,
            negative_prompt="background, blurry, low quality, distorted, ugly, bad anatomy, extra limbs",
            image=image,
            num_inference_steps=steps,
            guidance_scale=guidance_scale,
            controlnet_conditioning_scale=controlnet_scale,
            generator=torch.manual_seed(seed)
        )

        generated_image = result.images[0]
        yield "âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ!", generated_image

    except Exception as e:
        yield f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}", None

# ------------------------------------------------------
# Gradio UI êµ¬ì„±
# ------------------------------------------------------
CUSTOM_CSS = """
#centered-row {
    display: flex;
    justify-content: center;
    align-items: center;
    gap: 50px;
}

#big_sketch {
    width: 700px !important;
    height: 700px !important;
    max-width: 1000px !important;
    max-height: 1000px !important;
}

#small_upload {
    width: 500px !important;
    height: 500px !important;
    max-width: 500px !important;
    max-height: 500px !important;
}
"""

with gr.Blocks(css=CUSTOM_CSS) as demo:
    gr.Markdown("## ğŸ¨ AIKU - Pokemon & Crayon Doodle Diffusion")

    category = gr.Radio(
        choices=["í¬ì¼“ëª¬", "ì•„ë§ˆì¶”ì–´"],
        value="í¬ì¼“ëª¬",
        label="ìƒì„± ì¹´í…Œê³ ë¦¬ ì„ íƒ"
    )

    mode = gr.Radio(
        choices=["ìŠ¤ì¼€ì¹˜ ì‚¬ìš©", "ì—…ë¡œë“œ ì‚¬ìš©"],
        value="ì—…ë¡œë“œ ì‚¬ìš©",
        label="ì…ë ¥ ë°©ì‹ ì„ íƒ"
    )

    with gr.Row(elem_id="centered-row"):
        sketch = gr.Sketchpad(
            label="ğŸ–Œï¸ í‘ë°± ìŠ¤ì¼€ì¹˜",
            canvas_size=(700, 700),
            type="pil",
            visible=False,
            elem_id="big_sketch"
        )
        uploaded = gr.Image(
            label="ì´ë¯¸ì§€ ì—…ë¡œë“œ",
            type="pil",
            visible=True,
            elem_id="small_upload"
        )

    description = gr.Textbox(
        label="ì´ë¯¸ì§€ ì„¤ëª… ì…ë ¥ (ë‹¨ì–´ë¡œ ì…ë ¥)",
        placeholder="ì˜ˆ: tiger"
    )

    submit = gr.Button("ì œì¶œ")
    result = gr.Textbox(label="ì§„í–‰ ìƒíƒœ", interactive=True)
    result_image = gr.Image(label="ìƒì„±ëœ ì´ë¯¸ì§€", type="pil")

    def toggle_inputs(mode):
        if mode == "ìŠ¤ì¼€ì¹˜ ì‚¬ìš©":
            return gr.update(visible=True, value=None), gr.update(visible=False)
        else:
            return gr.update(visible=False), gr.update(visible=True)

    mode.change(
        fn=toggle_inputs,
        inputs=[mode],
        outputs=[sketch, uploaded]
    )

    submit.click(
        fn=run_inference,
        inputs=[category, mode, sketch, uploaded, description],
        outputs=[result, result_image]
    )

demo.launch(server_name="0.0.0.0", server_port=7860)
